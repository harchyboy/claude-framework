# Claude Code — Project Instructions

> Generated by Hartz Claude Framework. Edit the PROJECT CONTEXT section for this specific project.
> Framework docs: https://github.com/hartz-ai/claude-framework

---

## PROJECT CONTEXT

```
Project name:    [REPLACE: e.g. UNION Spaces Core]
Description:     [REPLACE: e.g. Commercial real estate CRM for UNION Spaces London]
Tech stack:      [REPLACE: e.g. React 18, TypeScript 5, Supabase, Tailwind CSS]
Primary domain:  [REPLACE: e.g. commercial-real-estate / client-automation / ai-training]
Repo:            [REPLACE: GitHub URL]
```

---

## BEHAVIOURAL RULES

These rules apply to every session, every agent, every task. No exceptions.

### File discipline
- ALWAYS read a file before editing it — never assume its current contents
- NEVER create new files unless absolutely necessary — prefer editing existing files
- NEVER proactively create documentation files unless explicitly asked
- NEVER save working files to the repository root
- NEVER commit secrets, API keys, credentials, or `.env` files
- ALWAYS verify imports resolve before committing TypeScript changes

### Communication (Agent Teams)
- Your text output is NOT visible to teammates — you MUST use Teammate `write()` to communicate
- Use `write()` to specific teammates over `broadcast()` — broadcast sends N messages for N agents
- When reporting results, always include specific file paths, line numbers, and code snippets
- ALL agent spawns + task creates + tool calls go in ONE message for true parallelism

### Quality discipline
- ALWAYS run existing tests before AND after making changes
- NEVER leave `TODO` comments in committed code without a linked task in the task list
- ALWAYS update `PROGRESS.md` after completing any task
- If stuck on the same bug for more than 3 attempts: document it in `docs/failed-approaches.md`, try a fundamentally different strategy
- ALWAYS check `docs/solutions/` for known patterns before implementing a novel solution
- NEVER retry a known failed approach — check `docs/failed-approaches.md` first

### Coordination discipline (multi-agent)
- ALL spawns + task creates in ONE message for true parallelism — never sequential spawning
- Enable delegate mode (`Shift+Tab`) immediately when starting an Agent Team
- NEVER continuously poll after spawning — set expectations, then wait for reports
- Claim tasks by updating owner BEFORE starting work to prevent conflicts
- Release task locks on completion or abandonment

---

## MODEL ROUTING

| Task | Model | Rationale |
|------|-------|-----------|
| Orchestrator / team lead | **Opus** | Strategic reasoning, synthesis |
| Architecture review | **Opus** | High-stakes design decisions |
| Security audit | **Opus** | Vulnerability assessment |
| Feature implementation | **Sonnet** | Strong code quality, cost-efficient |
| Code review (all reviewers) | **Sonnet** | Complex reasoning without Opus cost |
| Codebase exploration / grep | **Haiku** | Fast, read-only, minimal cost |
| Test generation | **Haiku** | Mechanical, pattern-based |
| Documentation updates | **Haiku** | Low complexity |

---

## WORKFLOW DECISION GUIDE

### Use Ralph loop (`scripts/ralph.sh`) when:
- Building a feature with 3+ user stories
- Fixing a bug with clear acceptance criteria
- Any task estimated >30 min of AI work
- You want to run unattended overnight

### Use Agent Teams when:
- Code review requiring multiple simultaneous perspectives
- Debugging with no obvious root cause (competing hypotheses)
- Architecture decisions with real tradeoffs to evaluate
- 3+ independent files needing coordinated changes

### Stay single-agent when:
- Single file edits or targeted bug fixes
- Documentation-only changes
- Configuration updates
- Quick exploration or grep searches
- Sequential data processing pipelines

### Use subagents (within a session) when:
- Delegating a focused chunk of work mid-session
- Running tests or bash commands in parallel
- Generating a plan before implementation

---

## AGENT TEAMS — ORCHESTRATION PATTERNS

### Leader pattern (feature development)
```
Orchestrator (Opus, delegate mode ON)
├── frontend-agent   → owns src/components/, src/pages/
├── backend-agent    → owns src/api/, src/lib/
└── test-agent       → owns src/__tests__/, e2e/
```
Workers never touch each other's directories. Findings shared via write().

### Swarm pattern (code review)
Spawn all review agents simultaneously in ONE message:
```
security-sentinel + typescript-reviewer + architecture-strategist
+ performance-oracle + data-integrity-guardian + accessibility-reviewer
```
Each claims independent review tasks. Lead synthesises findings into P1/P2/P3 report.

### Debate pattern (debugging / architecture)
Spawn 3 agents, each with a different root-cause hypothesis. Have them challenge
each other's conclusions via broadcast(). Lead picks the strongest argument.

### Watchdog pattern (risky refactors)
Spawn implementation agent with `planModeRequired: true`.
Spawn watchdog agent to monitor changes and flag scope creep.
Lead approves plans before any file writes.

### Wave decomposition (large features)
```
Wave 1 (parallel): types, schemas, utility functions — no shared state
Wave 2 (parallel): components, API routes, DB functions — file ownership assigned
Wave 3 (parallel): integration, wiring state to API — depends on Wave 2
Wave 4 (parallel): unit tests, integration tests — depends on Wave 3
Wave 5 (sequential): review, documentation, cleanup
```
Each wave's tasks run in parallel. Waves execute sequentially.

---

## SELF-ORGANISING WORKER PREAMBLE

When spawning teammates in an Agent Team, give each this preamble (replace placeholders):

```
You are [AGENT_NAME] on team [TEAM_NAME].
Your specialisation: [ROLE_DESCRIPTION]
Your file ownership: [DIRECTORY_OR_FILE_LIST]

Work loop:
1. Check task list for pending, unowned tasks matching your role
2. If found:
   - Claim: TaskUpdate({ taskId: "X", owner: "[AGENT_NAME]" })
   - Start: TaskUpdate({ taskId: "X", status: "in_progress" })
   - Execute the work
   - Complete: TaskUpdate({ taskId: "X", status: "completed" })
   - Report findings to team-lead via Teammate write()
   - Return to step 1
3. If no tasks available:
   - Notify team-lead you are idle via write()
   - Wait 30 seconds and check again (up to 3 times)
   - If still nothing, request shutdown

Rules:
- Read files before editing them
- Run tests after any code changes
- NEVER edit files outside your ownership boundary
- Communicate results via write(), not text output
```

---

## EXTERNAL MEMORY PROTOCOL

Every agent, every session, follows this protocol:

**Before starting work:**
1. Read `PROGRESS.md` — understand current state and what's already been tried
2. Search `docs/solutions/` for patterns relevant to your task
3. Check `docs/failed-approaches.md` — never retry a known failure
4. Check `current_tasks/` — do NOT claim a task already locked

**After completing work:**
1. Update `PROGRESS.md` with: what changed, what's next, any blockers
2. If you solved a non-obvious problem, create a `docs/solutions/YYYY-MM-DD-slug.md` entry
3. If something didn't work after 3 attempts, add to `docs/failed-approaches.md`
4. Remove your lock file from `current_tasks/` after committing

**Learnings file format** (`docs/solutions/YYYY-MM-DD-slug.md`):
```yaml
---
title: "Brief description of the solution"
category: bug-fix | pattern | workaround | architecture-decision
tags: [supabase, auth, typescript, react, rls]
date: YYYY-MM-DD
severity: p1 | p2 | p3
---

## Problem
What went wrong and how it manifested.

## Root cause
Why it happened.

## Solution
What fixed it, with code snippets.

## Prevention
How to avoid this class of problem in the future.
```

---

## QUALITY GATES

### Pre-commit (run before every commit)
```bash
bash scripts/quality-gate.sh
```
Checks: TypeScript compile → ESLint → Tests → No secrets in diff

### Code review scoring (8 dimensions, threshold: 0.85)
When evaluating completed work, score these dimensions 0.0–1.0:

| Dimension | What to check |
|-----------|---------------|
| Correctness | Works as specified, handles edge cases |
| Test quality | Edge cases covered, adequate coverage |
| Type safety | No `any`, proper generics, exhaustive checks |
| Security | RLS policies, input validation, auth checks |
| Performance | No N+1 queries, proper memoization |
| Error handling | Graceful failures, user-facing messages |
| Maintainability | Clear naming, DRY, single responsibility |
| Documentation | JSDoc on public APIs, README updated |

If `overall_score < 0.85`, create a remediation task with specific fix instructions before marking complete.

### Review output format
All review agents report findings in this format:
```
P1 — CRITICAL (must fix before merge):
[ ] Issue description (agent-name) — file.ts:42

P2 — IMPORTANT (should fix, can be follow-up task):
[ ] Issue description (agent-name) — file.ts:42

P3 — MINOR (nice to have):
[ ] Issue description (agent-name) — file.ts:42

LEARNINGS CHECK:
[ ] Related past issue found: docs/solutions/2025-03-auth-bypass.md
```

---

## RALPH LOOP (autonomous development)

For unattended autonomous development:

```bash
bash scripts/ralph.sh [max_iterations] [options]

Options:
  --max-plan          Track iterations not cost (Anthropic Max users)
  --max-cost <n>      Hard stop if cost exceeds $n
  --quality-gate      Run typecheck/lint/tests after each iteration
  --review            Spawn review agent after implementation
  --strict            Fail on lint warnings
```

**Each iteration:**
1. `git pull origin main` — sync with remote
2. Read `PROGRESS.md` and `docs/solutions/` — bootstrap context
3. Check `current_tasks/` — skip locked tasks
4. Pick highest-priority uncomplete task from PRD
5. Claim it: `echo "task description" > current_tasks/task-name.txt && git add && git commit && git push`
6. Implement with tests
7. Run quality gate — fix failures before continuing
8. Update `PROGRESS.md`
9. Commit and push
10. Remove lock file, commit

**If push fails (conflict):** another agent claimed the task — pick a different one.

---

## PRD FORMAT

Create PRDs at `scripts/ralph-moss/prds/[feature-name]/prd.json`:

```json
{
  "project": "ProjectName",
  "branchName": "ralph-moss/feature-name",
  "description": "Feature description",
  "userStories": [
    {
      "id": "US-001",
      "title": "Story title",
      "description": "As a [user], I want [feature] so that [benefit]",
      "acceptanceCriteria": [
        "Specific criterion 1",
        "Specific criterion 2",
        "TypeScript compiles without errors",
        "All existing tests pass"
      ],
      "priority": 1,
      "passes": false,
      "notes": ""
    }
  ]
}
```

**Story sizing rule:** each story MUST be completable in ONE iteration (~10 min of AI work).
Split anything that sounds like: "Build the entire X", "Add authentication", "Refactor the Y".

---

## TECH STACK CONVENTIONS

> Fill in this section for each project. Defaults shown for React/TypeScript/Supabase.

### TypeScript
- Strict mode — no `any` without a justification comment
- Exhaustive checks on discriminated unions
- Generate Supabase types: `npx supabase gen types typescript`
- All API responses typed — never `unknown` without narrowing

### React
- Functional components only — no class components
- Error boundaries at route level
- Lazy loading for routes: `React.lazy(() => import('./pages/X'))`
- State co-located at lowest necessary level

### Supabase
- All DB access via `src/lib/supabase.ts` — never direct fetch to PostgREST
- RLS policies MANDATORY on all tables — test them
- Edge Functions for server-side logic
- Migrations versioned in `supabase/migrations/`
- Test RLS after any table or policy change

### Testing
- Unit/integration: Vitest + React Testing Library
- E2E: Playwright
- Coverage targets: 80% business logic, 60% UI components
- Test files colocated: `Auth.tsx` → `__tests__/Auth.test.tsx`
- Machine-parseable output: errors prefixed with `ERROR:` for grep

### Git conventions
- Branch: `feature/US-001-brief-description` or `fix/bug-description`
- Commits: conventional commits (`feat:`, `fix:`, `refactor:`, `test:`, `docs:`)
- PR size: max 400 lines — decompose larger changes
- Never force-push to `main`

---

## COMPILER ORACLE PATTERN

When a task resists decomposition (many agents hitting the same blocking issue):
1. Identify a reference implementation or known-good version (production code, previous commit, test suite)
2. Use it to partition the problem: run the reference on 90% of files, your implementation on 10%
3. If mixed system works, the bug is not in your 10% — adjust partition
4. Delta debug until the failing subset is minimal
5. Fix the isolated root cause once — document in `docs/solutions/`

This pattern prevents N agents independently fixing the same bug and overwriting each other.
